{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b0b3370",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-06T13:45:32.777087Z",
     "iopub.status.busy": "2024-03-06T13:45:32.776379Z",
     "iopub.status.idle": "2024-03-06T13:45:42.873491Z",
     "shell.execute_reply": "2024-03-06T13:45:42.872732Z"
    },
    "papermill": {
     "duration": 10.106444,
     "end_time": "2024-03-06T13:45:42.875761",
     "exception": false,
     "start_time": "2024-03-06T13:45:32.769317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import torchmetrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "767dac67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-06T13:45:42.887958Z",
     "iopub.status.busy": "2024-03-06T13:45:42.887566Z",
     "iopub.status.idle": "2024-03-06T13:45:42.891712Z",
     "shell.execute_reply": "2024-03-06T13:45:42.890851Z"
    },
    "papermill": {
     "duration": 0.012188,
     "end_time": "2024-03-06T13:45:42.893676",
     "exception": false,
     "start_time": "2024-03-06T13:45:42.881488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR_PATH = 'voice-commands-classification-2025/train'\n",
    "TEST_DIR_PATH = 'voice-commands-classification-2025/adv_test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4d072fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-06T13:45:42.905266Z",
     "iopub.status.busy": "2024-03-06T13:45:42.904947Z",
     "iopub.status.idle": "2024-03-06T13:45:42.909052Z",
     "shell.execute_reply": "2024-03-06T13:45:42.908237Z"
    },
    "papermill": {
     "duration": 0.011883,
     "end_time": "2024-03-06T13:45:42.910859",
     "exception": false,
     "start_time": "2024-03-06T13:45:42.898976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "N_WORKERS = 8\n",
    "N_CLASSES = 35\n",
    "EPOCHS = 50\n",
    "LR = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1dd123d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-06T13:45:42.922203Z",
     "iopub.status.busy": "2024-03-06T13:45:42.921905Z",
     "iopub.status.idle": "2024-03-06T13:45:42.976088Z",
     "shell.execute_reply": "2024-03-06T13:45:42.975189Z"
    },
    "papermill": {
     "duration": 0.061991,
     "end_time": "2024-03-06T13:45:42.977976",
     "exception": false,
     "start_time": "2024-03-06T13:45:42.915985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda:0')\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device('mps')\n",
    "\n",
    "DEVICE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfa0363c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-06T13:45:42.989858Z",
     "iopub.status.busy": "2024-03-06T13:45:42.989589Z",
     "iopub.status.idle": "2024-03-06T13:45:42.998694Z",
     "shell.execute_reply": "2024-03-06T13:45:42.997819Z"
    },
    "papermill": {
     "duration": 0.017209,
     "end_time": "2024-03-06T13:45:43.000555",
     "exception": false,
     "start_time": "2024-03-06T13:45:42.983346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SpeechCommandDataset(Dataset):\n",
    "    def __init__(self, dir_path, data, labels=None, dict_label_to_index=None, transform=None):\n",
    "        self.dir_path = dir_path\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.dict_label_to_index = dict_label_to_index\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.data[idx]\n",
    "        waveform = np.load(os.path.join(self.dir_path, file_name))\n",
    "        if waveform.shape[1] < 16000:\n",
    "            waveform = np.pad(\n",
    "                waveform, pad_width=((0, 0), (0, 16000 - waveform.shape[1])),\n",
    "                mode='constant',\n",
    "                constant_values=0\n",
    "            )\n",
    "\n",
    "        waveform = torch.from_numpy(waveform)\n",
    "\n",
    "        if self.transform != None:\n",
    "            spectrogram = self.transform(waveform)\n",
    "        \n",
    "        out_labels = []\n",
    "        if self.labels is not None:\n",
    "            if self.labels[idx] in self.dict_label_to_index:\n",
    "                out_labels = self.dict_label_to_index[self.labels[idx]]\n",
    "\n",
    "        return waveform, spectrogram, out_labels, int(file_name.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a0628ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-06T13:45:43.012269Z",
     "iopub.status.busy": "2024-03-06T13:45:43.011734Z",
     "iopub.status.idle": "2024-03-06T13:45:43.193184Z",
     "shell.execute_reply": "2024-03-06T13:45:43.192294Z"
    },
    "papermill": {
     "duration": 0.18942,
     "end_time": "2024-03-06T13:45:43.195227",
     "exception": false,
     "start_time": "2024-03-06T13:45:43.005807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stop': 0,\n",
       " 'go': 1,\n",
       " 'right': 2,\n",
       " 'dog': 3,\n",
       " 'left': 4,\n",
       " 'yes': 5,\n",
       " 'zero': 6,\n",
       " 'four': 7,\n",
       " 'bird': 8,\n",
       " 'cat': 9,\n",
       " 'five': 10,\n",
       " 'off': 11,\n",
       " 'learn': 12,\n",
       " 'six': 13,\n",
       " 'two': 14,\n",
       " 'on': 15,\n",
       " 'up': 16,\n",
       " 'three': 17,\n",
       " 'nine': 18,\n",
       " 'one': 19,\n",
       " 'follow': 20,\n",
       " 'wow': 21,\n",
       " 'seven': 22,\n",
       " 'sheila': 23,\n",
       " 'down': 24,\n",
       " 'no': 25,\n",
       " 'bed': 26,\n",
       " 'eight': 27,\n",
       " 'house': 28,\n",
       " 'tree': 29,\n",
       " 'visual': 30,\n",
       " 'forward': 31,\n",
       " 'marvin': 32,\n",
       " 'backward': 33,\n",
       " 'happy': 34}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\n",
    "    os.path.join(TRAIN_DIR_PATH, 'metadata.csv')\n",
    ")\n",
    "dict_label_to_index = {}\n",
    "dict_index_to_label = {}\n",
    "for index, key in enumerate(df_train['label'].unique()):\n",
    "    dict_label_to_index[key] = index\n",
    "    dict_index_to_label[index] = key\n",
    "\n",
    "dict_label_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b7fa28d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-06T13:45:43.207819Z",
     "iopub.status.busy": "2024-03-06T13:45:43.207552Z",
     "iopub.status.idle": "2024-03-06T13:45:43.228725Z",
     "shell.execute_reply": "2024-03-06T13:45:43.227945Z"
    },
    "papermill": {
     "duration": 0.029732,
     "end_time": "2024-03-06T13:45:43.230833",
     "exception": false,
     "start_time": "2024-03-06T13:45:43.201101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train_data, df_val_data = train_test_split(\n",
    "    df_train,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "train_data = df_train_data.file_name.values\n",
    "train_labels = df_train_data.label.values\n",
    "\n",
    "val_data = df_val_data.file_name.values\n",
    "val_labels = df_val_data.label.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f26cf6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-06T13:45:43.243027Z",
     "iopub.status.busy": "2024-03-06T13:45:43.242717Z",
     "iopub.status.idle": "2024-03-06T13:45:43.345101Z",
     "shell.execute_reply": "2024-03-06T13:45:43.344426Z"
    },
    "papermill": {
     "duration": 0.110838,
     "end_time": "2024-03-06T13:45:43.347191",
     "exception": false,
     "start_time": "2024-03-06T13:45:43.236353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_transforms = torch.nn.Sequential(\n",
    "    # torchaudio.transforms.MelSpectrogram(f_min=125, f_max=7500, normalized=True, n_mels=32)\n",
    "    torchaudio.transforms.MFCC(n_mfcc=32, log_mels=True)\n",
    ")\n",
    "\n",
    "val_transform = torch.nn.Sequential(\n",
    "    torchaudio.transforms.MelSpectrogram(),\n",
    "    # torchaudio.transforms.MFCC()\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    SpeechCommandDataset(\n",
    "        dir_path=TRAIN_DIR_PATH,\n",
    "        data=train_data,\n",
    "        labels=train_labels,\n",
    "        dict_label_to_index=dict_label_to_index,\n",
    "        transform=train_transforms\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=N_WORKERS\n",
    ")\n",
    "\n",
    "valid_dataloader = DataLoader(\n",
    "    SpeechCommandDataset(\n",
    "        dir_path=TRAIN_DIR_PATH,\n",
    "        data=val_data,\n",
    "        labels=val_labels,\n",
    "        dict_label_to_index=dict_label_to_index,\n",
    "        transform=train_transforms\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=N_WORKERS\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5a3106",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-06T13:45:43.360577Z",
     "iopub.status.busy": "2024-03-06T13:45:43.360319Z",
     "iopub.status.idle": "2024-03-06T13:45:48.026580Z",
     "shell.execute_reply": "2024-03-06T13:45:48.025581Z"
    },
    "papermill": {
     "duration": 4.675622,
     "end_time": "2024-03-06T13:45:48.029062",
     "exception": false,
     "start_time": "2024-03-06T13:45:43.353440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 1, 16000]) torch.Size([512, 1, 32, 81])\n",
      "tensor(1.0000) tensor(-1.)\n"
     ]
    }
   ],
   "source": [
    "for item in train_dataloader:\n",
    "    # print(item)\n",
    "    print(item[0].shape, item[1].shape)\n",
    "    print(item[0].max(), item[0].min())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e946e8b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-06T13:45:48.042392Z",
     "iopub.status.busy": "2024-03-06T13:45:48.042084Z",
     "iopub.status.idle": "2024-03-06T13:45:48.053947Z",
     "shell.execute_reply": "2024-03-06T13:45:48.053245Z"
    },
    "papermill": {
     "duration": 0.020696,
     "end_time": "2024-03-06T13:45:48.055763",
     "exception": false,
     "start_time": "2024-03-06T13:45:48.035067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class M5(nn.Module):\n",
    "    def __init__(self, n_input=1, n_output=35, stride=16, n_channel=32, sp_channel=32):\n",
    "        super().__init__()\n",
    "        # self.conv1 = nn.Conv1d(n_input, n_channel, kernel_size=80, stride=stride)\n",
    "        # self.bn1 = nn.BatchNorm1d(n_channel)\n",
    "        # self.pool1 = nn.MaxPool1d(3)\n",
    "        self.sp_conv2 = nn.Conv1d(n_channel, sp_channel, kernel_size=3, padding=1)\n",
    "        self.sp_bn2 = nn.BatchNorm1d(sp_channel)\n",
    "        self.sp_pool2 = nn.MaxPool1d(3)\n",
    "        self.sp_conv3 = nn.Conv1d(sp_channel, 2 * sp_channel, kernel_size=3, padding=1)\n",
    "        self.sp_bn3 = nn.BatchNorm1d(2 * sp_channel)\n",
    "        self.sp_pool3 = nn.MaxPool1d(3)\n",
    "        self.sp_conv4 = nn.Conv1d(2 * sp_channel, 2 * sp_channel, kernel_size=3)\n",
    "        self.sp_bn4 = nn.BatchNorm1d(2 * sp_channel)\n",
    "        self.sp_pool4 = nn.MaxPool1d(2)\n",
    "        self.sp_fc1 = nn.Linear(2 * sp_channel, n_output)\n",
    "\n",
    "        self.conv1 = nn.Conv1d(n_input, 64, kernel_size=80, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        # self.pool1 = nn.MaxPool1d(4)\n",
    "        # self.conv2 = nn.Conv1d(n_channel, n_channel, kernel_size=3)\n",
    "        # self.bn2 = nn.BatchNorm1d(n_channel)\n",
    "        # self.pool2 = nn.MaxPool1d(4)\n",
    "        # self.conv3 = nn.Conv1d(n_channel, 2 * n_channel, kernel_size=3)\n",
    "        # self.bn3 = nn.BatchNorm1d(2 * n_channel)\n",
    "        # self.pool3 = nn.MaxPool1d(4)\n",
    "        # self.conv4 = nn.Conv1d(2 * n_channel, 2 * n_channel, kernel_size=3)\n",
    "        # self.bn4 = nn.BatchNorm1d(2 * n_channel)\n",
    "        # self.pool4 = nn.MaxPool1d(4)\n",
    "        self.fc1 = nn.Linear(2 * n_channel, n_output)\n",
    "        self.lstm = nn.LSTM(64, 32, num_layers=2, batch_first=True, bidirectional=True)\n",
    "\n",
    "    def forward(self, x, sp):\n",
    "        # x = self.conv1(x)\n",
    "        \n",
    "        # x = F.relu(self.bn1(x))\n",
    "        # x = self.pool1(x)\n",
    "        sp = sp.squeeze(1)\n",
    "        # print(sp.shape)\n",
    "        sp = self.sp_conv2(sp)\n",
    "        \n",
    "        \n",
    "        sp = F.relu(self.sp_bn2(sp))\n",
    "        sp = self.sp_pool2(sp)\n",
    "        \n",
    "        \n",
    "        sp = self.sp_conv3(sp)\n",
    "        sp = F.relu(self.sp_bn3(sp))\n",
    "        sp = self.sp_pool3(sp)\n",
    "        # print(x.shape)\n",
    "        sp = self.sp_conv4(sp)\n",
    "        sp = F.relu(self.sp_bn4(sp))\n",
    "        sp = self.sp_pool4(sp)\n",
    "        # print(sp.shape)\n",
    "        sp = F.avg_pool1d(sp, sp.shape[-1])\n",
    "        # print(sp.shape)\n",
    "        sp = sp.permute(0, 2, 1)\n",
    "        # print(sp.shape)\n",
    "        # sp = self.sp_fc1(sp)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = x.transpose(-1, -2)\n",
    "        x, _ = self.lstm(x)\n",
    "        # print(x.shape)\n",
    "        x = x[:, -1, :].unsqueeze(1)\n",
    "        # print(x.shape)\n",
    "\n",
    "\n",
    "\n",
    "        # x = self.pool1(x)\n",
    "        # x = self.conv2(x)\n",
    "        # x = F.relu(self.bn2(x))\n",
    "        # x = self.pool2(x)\n",
    "        # x = self.conv3(x)\n",
    "        # x = F.relu(self.bn3(x))\n",
    "        # x = self.pool3(x)\n",
    "        # x = self.conv4(x)\n",
    "        # x = F.relu(self.bn4(x))\n",
    "        # x = self.pool4(x)\n",
    "        # x = F.avg_pool1d(x, x.shape[-1])\n",
    "        # x = x.permute(0, 2, 1)\n",
    "\n",
    "        # x = torch.stack((x, sp), dim=-1).reshape(x.shape[0], x.shape[1], 128)\n",
    "        # print(x.shape)\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1169527",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-06T13:45:48.068734Z",
     "iopub.status.busy": "2024-03-06T13:45:48.068275Z",
     "iopub.status.idle": "2024-03-06T13:45:48.228719Z",
     "shell.execute_reply": "2024-03-06T13:45:48.227732Z"
    },
    "papermill": {
     "duration": 0.169624,
     "end_time": "2024-03-06T13:45:48.230993",
     "exception": false,
     "start_time": "2024-03-06T13:45:48.061369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = M5(n_input=1, n_channel=32)\n",
    "model = model.to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a108d4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-06T13:45:48.243585Z",
     "iopub.status.busy": "2024-03-06T13:45:48.243288Z",
     "iopub.status.idle": "2024-03-06T13:45:48.850978Z",
     "shell.execute_reply": "2024-03-06T13:45:48.849952Z"
    },
    "papermill": {
     "duration": 0.616391,
     "end_time": "2024-03-06T13:45:48.853228",
     "exception": false,
     "start_time": "2024-03-06T13:45:48.236837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 35])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(4, 1, 16000)\n",
    "\n",
    "# print((torchaudio.transforms.MFCC()(input_image).shape))\n",
    "\n",
    "input_sp = train_transforms(input_image).to(DEVICE)\n",
    "# print(input_sp.shape)\n",
    "model = model.to(DEVICE)\n",
    "result = model(input_image.to(DEVICE), input_sp)\n",
    "\n",
    "print(result.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad01820d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-06T13:45:48.866933Z",
     "iopub.status.busy": "2024-03-06T13:45:48.866633Z",
     "iopub.status.idle": "2024-03-06T13:45:48.878490Z",
     "shell.execute_reply": "2024-03-06T13:45:48.877629Z"
    },
    "papermill": {
     "duration": 0.021282,
     "end_time": "2024-03-06T13:45:48.880369",
     "exception": false,
     "start_time": "2024-03-06T13:45:48.859087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model: nn.Module, train_data: DataLoader, valid_data: DataLoader):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0001)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    accuracy_train = torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=N_CLASSES).to(DEVICE)\n",
    "    accuracy_val = torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=N_CLASSES).to(DEVICE)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss = 0.0\n",
    "        val_loss = 0.0\n",
    "\n",
    "        model.train()\n",
    "        for x, x_sp, y, _ in train_data:\n",
    "            x = x.to(DEVICE)\n",
    "            x_sp = x_sp.to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_hat = model(x, x_sp).squeeze()\n",
    "            loss = criterion(y_hat, y)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * x.size(0)\n",
    "            _, preds = torch.max(y_hat, 1)\n",
    "\n",
    "            accuracy_train(\n",
    "                y_hat,\n",
    "                y\n",
    "            )\n",
    "\n",
    "        model.eval()\n",
    "        for x, x_sp, y, _ in valid_data:\n",
    "            x = x.to(DEVICE)\n",
    "            x_sp = x_sp.to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "\n",
    "            y_hat = model(x, x_sp).squeeze()\n",
    "            loss = criterion(y_hat, y)\n",
    "\n",
    "            val_loss += loss.item() * x.size(0)\n",
    "            _, preds = torch.max(y_hat, 1)\n",
    "\n",
    "            accuracy_val(\n",
    "                y_hat,\n",
    "                y\n",
    "            )\n",
    "\n",
    "        train_loss = train_loss / len(train_dataloader.dataset)\n",
    "        val_loss = val_loss / len(valid_dataloader.dataset)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {accuracy_train.compute():.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {accuracy_val.compute():.4f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38733d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-06T13:45:48.892825Z",
     "iopub.status.busy": "2024-03-06T13:45:48.892577Z",
     "iopub.status.idle": "2024-03-06T14:01:52.656517Z",
     "shell.execute_reply": "2024-03-06T14:01:52.655250Z"
    },
    "papermill": {
     "duration": 963.772813,
     "end_time": "2024-03-06T14:01:52.658802",
     "exception": false,
     "start_time": "2024-03-06T13:45:48.885989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Train Loss: 3.5005, Train Acc: 0.0363\n",
      "Val Loss: 3.4996, Val Acc: 0.0357\n",
      "Epoch 2/50\n",
      "Train Loss: 3.4985, Train Acc: 0.0370\n",
      "Val Loss: 3.4946, Val Acc: 0.0370\n",
      "Epoch 3/50\n",
      "Train Loss: 3.4957, Train Acc: 0.0374\n",
      "Val Loss: 3.4890, Val Acc: 0.0377\n",
      "Epoch 4/50\n",
      "Train Loss: 3.4934, Train Acc: 0.0378\n",
      "Val Loss: 3.4896, Val Acc: 0.0377\n",
      "Epoch 5/50\n",
      "Train Loss: 3.4907, Train Acc: 0.0380\n",
      "Val Loss: 3.4914, Val Acc: 0.0380\n",
      "Epoch 6/50\n",
      "Train Loss: 3.4905, Train Acc: 0.0381\n",
      "Val Loss: 3.4864, Val Acc: 0.0381\n",
      "Epoch 7/50\n",
      "Train Loss: 3.4813, Train Acc: 0.0386\n",
      "Val Loss: 3.4236, Val Acc: 0.0413\n",
      "Epoch 8/50\n",
      "Train Loss: 3.3871, Train Acc: 0.0413\n",
      "Val Loss: 3.3392, Val Acc: 0.0444\n",
      "Epoch 9/50\n",
      "Train Loss: 3.3400, Train Acc: 0.0438\n",
      "Val Loss: 3.3311, Val Acc: 0.0470\n",
      "Epoch 10/50\n",
      "Train Loss: 3.3205, Train Acc: 0.0461\n",
      "Val Loss: 3.3367, Val Acc: 0.0489\n",
      "Epoch 11/50\n",
      "Train Loss: 3.3233, Train Acc: 0.0480\n",
      "Val Loss: 3.2939, Val Acc: 0.0505\n",
      "Epoch 12/50\n",
      "Train Loss: 3.3822, Train Acc: 0.0486\n",
      "Val Loss: 3.4861, Val Acc: 0.0496\n",
      "Epoch 13/50\n",
      "Train Loss: 3.3896, Train Acc: 0.0494\n",
      "Val Loss: 3.2967, Val Acc: 0.0508\n",
      "Epoch 14/50\n",
      "Train Loss: 3.3231, Train Acc: 0.0506\n",
      "Val Loss: 3.3258, Val Acc: 0.0521\n"
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    model=model,\n",
    "    train_data=train_dataloader,\n",
    "    valid_data=valid_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a6adcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([35, 128])\n",
      "(tensor([[ 1.2025e-02,  2.2407e-02,  1.5784e-01,  ..., -3.0753e-01,\n",
      "          1.4213e-03,  1.3600e-01],\n",
      "        [-3.2666e-03,  7.6779e-01,  4.3384e-02,  ..., -1.7164e-01,\n",
      "          8.5756e-04,  3.5857e-02],\n",
      "        [-4.5114e-03,  1.5476e-01, -1.0518e-01,  ..., -1.6196e-01,\n",
      "          4.2925e-04,  3.3386e-01],\n",
      "        ...,\n",
      "        [-8.9999e-03,  6.1591e-02, -1.9614e-01,  ..., -6.4551e-01,\n",
      "         -2.7019e-04, -4.4770e-01],\n",
      "        [ 4.5856e-03,  2.4794e-01, -2.6212e-01,  ..., -4.3530e-01,\n",
      "          1.1133e-03,  6.2596e-01],\n",
      "        [-3.1596e-03, -3.0311e-01,  6.0339e-02,  ..., -9.0924e-03,\n",
      "         -8.0231e-04, -4.6914e-01]], device='cuda:0', grad_fn=<SplitBackward0>), tensor([[ 1.6582e-04,  5.4839e-01,  4.0255e-06,  ...,  4.9793e-01,\n",
      "          1.2330e-05, -1.2917e+00],\n",
      "        [ 2.5950e-05, -9.4370e-02,  3.1954e-06,  ..., -2.7839e-01,\n",
      "         -1.6746e-05, -3.2822e-01],\n",
      "        [-2.6792e-05,  5.8419e-01,  1.4849e-06,  ..., -1.3326e-01,\n",
      "         -3.5774e-05, -7.4425e-02],\n",
      "        ...,\n",
      "        [-1.8444e-04, -8.6969e-01, -1.3522e-06,  ..., -4.9404e-01,\n",
      "          3.9074e-05, -7.6822e-01],\n",
      "        [ 9.7349e-05, -1.5897e-01,  3.2769e-06,  ..., -2.8405e-01,\n",
      "         -2.1233e-05, -2.1969e-01],\n",
      "        [-5.7788e-06, -1.4514e+00, -2.5485e-06,  ..., -2.9010e-01,\n",
      "         -3.6218e-05, -1.6767e-02]], device='cuda:0', grad_fn=<SplitBackward0>))\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39mfc1\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mchunk(model\u001b[38;5;241m.\u001b[39mfc1\u001b[38;5;241m.\u001b[39mweight,\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(model.fc1.weight.shape)\n",
    "print(torch.chunk(model.fc1.weight,2, dim=-1))\n",
    "assert 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00ac6b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-06T14:01:52.681150Z",
     "iopub.status.busy": "2024-03-06T14:01:52.679846Z",
     "iopub.status.idle": "2024-03-06T14:01:52.702615Z",
     "shell.execute_reply": "2024-03-06T14:01:52.701847Z"
    },
    "papermill": {
     "duration": 0.035985,
     "end_time": "2024-03-06T14:01:52.704696",
     "exception": false,
     "start_time": "2024-03-06T14:01:52.668711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\n",
    "    os.path.join(TEST_DIR_PATH, 'metadata.csv')\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    SpeechCommandDataset(\n",
    "        dir_path=TEST_DIR_PATH,\n",
    "        data=df_test.file_name.values,\n",
    "        labels=None,\n",
    "        dict_label_to_index=dict_label_to_index,\n",
    "        # transform=train_transforms\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=N_WORKERS\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8a9fdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-06T14:01:52.725515Z",
     "iopub.status.busy": "2024-03-06T14:01:52.725230Z",
     "iopub.status.idle": "2024-03-06T14:02:03.862727Z",
     "shell.execute_reply": "2024-03-06T14:02:03.861553Z"
    },
    "papermill": {
     "duration": 11.150686,
     "end_time": "2024-03-06T14:02:03.865048",
     "exception": false,
     "start_time": "2024-03-06T14:01:52.714362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ENSEMBLE PREDICTIONS AND SUBMIT\n",
    "results = {\n",
    "    'id': [],\n",
    "    'label': []\n",
    "}\n",
    "\n",
    "model.eval()\n",
    "for x, y, ids in test_dataloader:\n",
    "    x = x.float().to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        y_hat = model(x).squeeze()\n",
    "        _, preds = torch.max(y_hat, 1)\n",
    "        for i in range(len(preds)):\n",
    "            results[\"id\"].append(ids[i].item())\n",
    "            results[\"label\"].append(dict_index_to_label[int(preds[i].item())])\n",
    "        \n",
    "\n",
    "pd.DataFrame(results).to_csv(\n",
    "    'submission.csv',\n",
    "    columns=['id', 'label'],\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2db41d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-06T14:02:03.886762Z",
     "iopub.status.busy": "2024-03-06T14:02:03.886318Z",
     "iopub.status.idle": "2024-03-06T14:02:03.893059Z",
     "shell.execute_reply": "2024-03-06T14:02:03.892174Z"
    },
    "papermill": {
     "duration": 0.020278,
     "end_time": "2024-03-06T14:02:03.895071",
     "exception": false,
     "start_time": "2024-03-06T14:02:03.874793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "\n",
    "FileLink(r'submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 7876483,
     "sourceId": 71916,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "deep_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 996.684779,
   "end_time": "2024-03-06T14:02:06.730261",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-06T13:45:30.045482",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
